{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import time\n",
    "import glob\n",
    "import os\n",
    "from numpy.linalg import inv\n",
    "from bidict import bidict\n",
    "\n",
    "# user-defined\n",
    "import sys\n",
    "sys.path.append('/Users/cheng/Google Drive/PhD/Research/Portfolio Selection via TBN/codes/')\n",
    "from module import *\n",
    "from module.backtesting import *\n",
    "from module.agent_network import *\n",
    "from module.environment import market_envrionment\n",
    "from module.data_handler import *\n",
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "# visulization\n",
    "# import igraph\n",
    "# import cairocffi\n",
    "# import cairo\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# \n",
    "from scipy.sparse.csgraph import minimum_spanning_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notation\n",
    "$y_{it}$: the return on stock $i$ during period $t$, with $1 \\leq i \\leq N, 1 \\leq t \\leq T$\n",
    "\n",
    "$\\bar{y}$: the sample average of the returns of stock $i$, that is $\\bar{y}_{i}=T^{-1} \\sum_{t=1}^{T} y_{i t}$\n",
    "\n",
    "$\\Sigma$: the population (or true) covariance matrix\n",
    "\n",
    "$\\sigma_{ij}$: entries of $\\Sigma$\n",
    "\n",
    "$S$: the sample covariance matrix\n",
    "\n",
    "$s_{ij}$: entries of $S$\n",
    "\n",
    "$r_{i j}=\\frac{s_{i j}}{\\sqrt{s_{i i} s_{j j}}}$\n",
    "\n",
    "$\\bar{r}=\\frac{2}{(N-1) N} \\sum_{i=1}^{N-1} \\sum_{j=i+1}^{N} r_{i j}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. estimator for $\\pi_T$\n",
    "$\\hat{\\pi}_{T}:=\\sum_{i=1}^{N} \\sum_{j=1}^{N} \\hat{\\pi}_{i j}^{T} \\quad$\n",
    "\n",
    "$\\hat{\\pi}_{i j}=\\frac{1}{T} \\sum_{t=1}^{T}\\left\\{\\left(y_{i t}-\\bar{y}_{i}\\right)\\left(y_{j t}-\\bar{y}_{j} .\\right)-s_{i j}\\right\\}^{2}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pi(stock_returns):\n",
    "\n",
    "    # init\n",
    "    # symbols = stock_returns.columns\n",
    "    y = stock_returns.values\n",
    "    y_hat = np.average(y, axis=0)\n",
    "    s = stock_returns.cov().values\n",
    "    T = stock_returns.shape[0]\n",
    "    N = stock_returns.shape[1]\n",
    "    pi = []\n",
    "\n",
    "    # calculation\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            pi_ij = []\n",
    "            for t in range(T):\n",
    "                tmp = (y[t, j] - y_hat[j]) * (y[t, i] - y_hat[i]) - s[i, j]\n",
    "                pi_ij.append(tmp ** 2)\n",
    "            pi_ij = np.average(pi_ij)\n",
    "            pi.append(pi_ij)\n",
    "    pi = np.sum(pi)\n",
    "    \n",
    "    return pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.021773118708330652"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pi(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 estimator for $\\gamma_T$\n",
    "$\\hat{\\gamma}_{T}:=\\sum_{i=1}^{N} \\sum_{j=1}^{N}\\left(f_{i j}^{T}-s_{i j}^{T}\\right)^{2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gamma(stock_returns, shrink_target_cor):\n",
    "\n",
    "    # init\n",
    "    # symbols = stock_returns.columns\n",
    "    f = shrink_target_cor.values\n",
    "    s = stock_returns.cov().values\n",
    "    N = stock_returns.shape[1]\n",
    "    D = x.std().values # (non-annualized) std\n",
    "    f = np.diag(D) @ f @ np.diag(D)\n",
    "    gamma_ij = []\n",
    "\n",
    "    # calculation\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            tmp = f[i, j] - s[i, j]\n",
    "            gamma_ij.append(tmp ** 2)\n",
    "    gamma = np.sum(gamma_ij)\n",
    "    \n",
    "    return gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0005534544826441096"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_gamma(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. estimator for $\\rho_T$\n",
    "$\\hat{\\rho}=\\sum_{i=1}^{N} \\hat{\\pi}_{i i}+\\sum_{i=1}^{N} \\sum_{j=1, j \\neq i}^{N} \\frac{\\bar{r}}{2}\\left(\\sqrt{\\frac{s_{j j}}{s_{i i}}} \\hat{\\vartheta}_{i i, i j}+\\sqrt{\\frac{s_{i i}}{s_{j j}} \\hat{\\vartheta}_{j j, i j}}\\right)$\n",
    "\n",
    "where\n",
    "\n",
    "$\\hat{\\vartheta}_{i i, i j}=\\frac{1}{T} \\sum^{T}\\left\\{\\left(y_{i t}-\\bar{y}_{i}\\right)^{2}-s_{i i}\\right\\}\\left\\{\\left(y_{i t}-\\bar{y}_{i} \\cdot\\right)\\left(y_{j t}-\\bar{y}_{j}\\right)-s_{i j}\\right\\}$\n",
    "\n",
    "$\\hat{\\vartheta}_{j j, i j}=\\frac{1}{T} \\sum^{T}\\left\\{\\left(y_{j t}-\\bar{y}_{j}\\right)^{2}-s_{j j}\\right\\}\\left\\{\\left(y_{i t}-\\bar{y}_{i} .\\right)\\left(y_{j t}-\\bar{y}_{j}\\right)-s_{i j}\\right\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rho(stock_returns):\n",
    "    # init\n",
    "    y = stock_returns.values\n",
    "    y_hat = np.average(y, axis=0)\n",
    "    s = stock_returns.cov().values\n",
    "    T = stock_returns.shape[0]\n",
    "    N = stock_returns.shape[1]\n",
    "    theta_i = np.zeros([N, N])\n",
    "    theta_j = np.zeros([N, N])\n",
    "    theta = np.zeros([N, N])\n",
    "    r = np.zeros([N, N])\n",
    "    pi = np.zeros([N, N])\n",
    "\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            theta_ii = []\n",
    "            theta_jj = []\n",
    "            pi_ij = []\n",
    "            for t in range(T):\n",
    "                tmp = (y[t, j] - y_hat[j]) * (y[t, i] - y_hat[i]) - s[i, j]\n",
    "                \n",
    "                tmp_ii = ((y[t, i] - y_hat[i]) ** 2 - s[i, i]) * ((y[t, i] - y_hat[i]) * (y[t, j] - y_hat[j]) - s[i, j])\n",
    "                tmp_jj = ((y[t, j] - y_hat[j]) ** 2 - s[j, j]) * ((y[t, i] - y_hat[i]) * (y[t, j] - y_hat[j]) - s[i, j])\n",
    "\n",
    "                theta_ii.append(tmp_ii)\n",
    "                theta_jj.append(tmp_jj)\n",
    "                pi_ij.append(tmp ** 2)\n",
    "\n",
    "            pi_ij = np.average(pi_ij)\n",
    "            pi[i, j] = pi_ij\n",
    "\n",
    "            r_ij = s[i, j] / np.sqrt(s[i, i] * s[j, j])\n",
    "            r[i, j] = r_ij\n",
    "\n",
    "            theta_ii = np.average(theta_ii)\n",
    "            theta_jj = np.average(theta_jj)\n",
    "\n",
    "            theta_i[i, j] = theta_ii\n",
    "            theta_j[i, j] = theta_jj\n",
    "\n",
    "    r_sum_off_diag = np.sum(r - np.diag(np.diag(r))) / 2\n",
    "    r_bar = (2 / ((N - 1) * N)) * r_sum_off_diag\n",
    "\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            tmp = (r_bar / 2) * (np.sqrt(s[j, j] / s[i, i]) * theta_i[i, j] + np.sqrt(s[i, i] / s[j, j]) * theta_j[i, j])\n",
    "            theta[i, j] = tmp\n",
    "\n",
    "    np.fill_diagonal(theta, 0)\n",
    "    rho = np.sum(np.diag(pi)) + np.sum(theta)\n",
    "\n",
    "    return rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0028740878014524613"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rho(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. shrinkage intensity $\\kappa$\n",
    "\n",
    "$\\hat{\\kappa}=\\frac{\\hat{\\pi}-\\hat{\\rho}}{\\hat{\\gamma}}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kappa(stock_returns, shrink_target):\n",
    "    pi = get_pi(stock_returns)\n",
    "    rho = get_rho(stock_returns)\n",
    "    gamma = get_gamma(stock_returns, shrink_target)\n",
    "    #T = stock_returns.shape[0]\n",
    "\n",
    "    # bound\n",
    "    #gamma_tilde = (pi - rho) / (T * nu)\n",
    "    #gamma = np.max([gamma_tilde, 0])\n",
    "    #gamma = np.min([gamma, 1])\n",
    "    kappa = (pi - rho) / gamma\n",
    "\n",
    "    return kappa "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt = vectorized_backtesting(150)\n",
    "db = data_handler()\n",
    "x = bt.stocks_returns_aggregate.loc[2017]\n",
    "y = bt.tbn_combined.loc[2017]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "kappa = get_kappa(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "kappa_list = [get_kappa(bt.stocks_returns_aggregate.loc[year], bt.tbn_combined.loc[year]) for year in range(1996, 2017)]\n",
    "kappa_array = np.array(kappa_list) / 252\n",
    "kappa_df = pd.DataFrame(kappa_array, index=range(1996, 2017))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Shrink_to_TBN(vectorized_backtesting):\n",
    "    '''\n",
    "    Linear shrinkage method(ledoit) that shrink to TBN\n",
    "    '''\n",
    "    def get_portfolio(self, year):\n",
    "        alpha = kappa_df.loc[year - 1].values[0] #unsafe\n",
    "        covariance_shrunk = self.get_shrank_cov(correlation_matrix=self.correlation_aggregate.loc[year - 1].values,\\\n",
    "                                                shrink_target=self.tbn_combined.loc[year - 1].values,\\\n",
    "                                                volatility_vector=self.volatility_aggregate.loc[year - 1].values,\n",
    "                                                a=alpha)\n",
    "        portfolio = self.get_GMVP(covariance_matrix = covariance_shrunk)\n",
    "        return portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_backtesting_performance_vector(strategy_object: object) -> np.array:\n",
    "    '''\n",
    "    Given a portfolio stratgy, the Sharpe ratio and average turnover are returned\n",
    "    '''\n",
    "\n",
    "    # backtesting period\n",
    "    year_start = 2001\n",
    "    year_end = 2017\n",
    "\n",
    "    # get backtesting time series\n",
    "    portfolio_returns_vector = strategy_object.get_portfolio_daily_return(year_start, year_end)\n",
    "    sharpe_ratio = strategy_object.get_sharpe_ratio()\n",
    "    turnover_vector = strategy_object.get_turn_over_for_each_period()\n",
    "\n",
    "    # get backtesting performance indicator\n",
    "    #sharpe_ratio = np.mean(sharpe_ratio_vector)\n",
    "    turnover = np.mean(turnover_vector)\n",
    "\n",
    "    return np.array([sharpe_ratio, turnover])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/cheng/Google Drive/PhD/Research/Portfolio Selection via TBN/codes/')\n",
    "from module.strategy import *\n",
    "from itertools import chain\n",
    "import nonlinshrink as nls\n",
    "from sklearn.covariance import LedoitWolf\n",
    "from sklearn.covariance import OAS\n",
    "from scipy.stats import moment\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from module.data_handler import data_handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sharpe ratio</th>\n",
       "      <th>Turnover</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>shrink 0 pct</th>\n",
       "      <td>0.803892</td>\n",
       "      <td>3.486161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shrink 50 pct</th>\n",
       "      <td>0.698904</td>\n",
       "      <td>0.242921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shrink 100 pct</th>\n",
       "      <td>0.677564</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shrink ledoit</th>\n",
       "      <td>0.869363</td>\n",
       "      <td>2.248338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shrink 0 pct tbn</th>\n",
       "      <td>0.803892</td>\n",
       "      <td>3.486161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shrink 50 pct tbn</th>\n",
       "      <td>0.907298</td>\n",
       "      <td>0.980764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shrink 100 pct tbn</th>\n",
       "      <td>0.728605</td>\n",
       "      <td>0.242698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shrink_tbn</th>\n",
       "      <td>0.840168</td>\n",
       "      <td>3.009054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Sharpe ratio  Turnover\n",
       "shrink 0 pct            0.803892  3.486161\n",
       "shrink 50 pct           0.698904  0.242921\n",
       "shrink 100 pct          0.677564  0.000000\n",
       "shrink ledoit           0.869363  2.248338\n",
       "shrink 0 pct tbn        0.803892  3.486161\n",
       "shrink 50 pct tbn       0.907298  0.980764\n",
       "shrink 100 pct tbn      0.728605  0.242698\n",
       "shrink_tbn              0.840168  3.009054"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# strategy agents\n",
    "sample_size = 150\n",
    "shrink_0_pct = Shrink_0(sample_size)\n",
    "shrink_50_pct = Shrink_50(sample_size)\n",
    "shrink_100_pct = Shrink_100(sample_size)\n",
    "shrink_ledoit = Linear_shrink_ledoit(sample_size)\n",
    "\n",
    "shrink_0_pct_tbn = Shrink_0_tbn(sample_size)\n",
    "shrink_50_pct_tbn = Shrink_50_tbn(sample_size)\n",
    "shrink_100_pct_tbn = Shrink_100_tbn(sample_size)\n",
    "shrink_tbn = Shrink_to_TBN(sample_size)\n",
    "\n",
    "# strategy vector\n",
    "strategy_dict = {'shrink 0 pct': shrink_0_pct, \n",
    "                       'shrink 50 pct': shrink_50_pct,\n",
    "                       'shrink 100 pct': shrink_100_pct, \n",
    "                       'shrink ledoit': shrink_ledoit, \n",
    "                       'shrink 0 pct tbn': shrink_0_pct_tbn, \n",
    "                       'shrink 50 pct tbn': shrink_50_pct_tbn, \n",
    "                       'shrink 100 pct tbn': shrink_100_pct_tbn, \n",
    "                       'shrink_tbn': shrink_tbn\n",
    "}\n",
    "\n",
    "# backtest strategies\n",
    "backtest_performance_dict = {strategy_name: get_backtesting_performance_vector(strategy) for strategy_name, strategy in strategy_dict.items()}\n",
    "backtest_performance_df = pd.DataFrame(backtest_performance_dict).T\n",
    "backtest_performance_df.columns = ['Sharpe ratio', 'Turnover']\n",
    "backtest_performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'performance_table_150_new'\n",
    "label = 'tbl:sample 150 new'\n",
    "caption = 'Backtesting performance table on 150 companies from S\\&P 500 new'\n",
    "\n",
    "output_file_path = '/Users/cheng/Dropbox/Apps/Overleaf/Weekly Report Cheng/' + '/' + file_name + '.tex'\n",
    "caption = r'\\textbf{' + file_name + r'} \\\\ ' + caption\n",
    "                \n",
    "latex_table = backtest_performance_df.to_latex(output_file_path, \n",
    "                        float_format=\"%.3f\", \n",
    "                        caption=caption, \n",
    "                        label=label,\n",
    "                        position = 'h!')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "33f99ea47d1967c482d1a96e8f57146526516fa4859dddae9b508497402c9084"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('portfolio': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
