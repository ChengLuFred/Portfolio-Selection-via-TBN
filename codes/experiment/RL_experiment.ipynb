{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import gym\n",
    "import tianshou as ts\n",
    "import torch, numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tianshou.utils import BasicLogger\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "test = [(1,2,3), (2,3,4), (3,4,5), (4,5,6)]\n",
    "for item in zip(*test):\n",
    "    print(item)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1, 2, 3, 4)\n",
      "(2, 3, 4, 5)\n",
      "(3, 4, 5, 6)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(*test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Self-defined experiment"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from module import *\n",
    "from module.agent_network import *\n",
    "from module.environment import market_envrionment\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "tf.config.run_functions_eagerly(True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# initialization for agent and environment\n",
    "env = market_envrionment()\n",
    "state_size = env.observation_space[0] # given from environment\n",
    "action_size = env.action_space.shape[0]\n",
    "agent = DQNAgent(state_size, action_size)\n",
    "\n",
    "# hyper-parameter\n",
    "done = False\n",
    "batch_size = 5\n",
    "history_1 = []\n",
    "EPISODES = 100\n",
    "\n",
    "for e in tqdm(range(EPISODES)): # one episode is M trading years in a period\n",
    "    \n",
    "    # initialize state\n",
    "    state = env.reset()\n",
    "    state = np.reshape(state, [1, state_size]) # an array containing only one array [[a,b,c,d]]\n",
    "    rewards = 0\n",
    "    \n",
    "    for time in range(17): # how many years in a training period\n",
    "\n",
    "        # take an action\n",
    "        action = agent.act(state)\n",
    "        \n",
    "        # environment responds to the action and return new state and reward\n",
    "        next_state, reward, done = env.step(action)\n",
    "        \n",
    "        # record reward\n",
    "        rewards += reward\n",
    "        \n",
    "        # reshape state(can be reshaped within env)\n",
    "        next_state = np.reshape(next_state, [1, state_size]) # an 1 x n 2d array\n",
    "        \n",
    "        # record the experience for replay\n",
    "        agent.memorize(state, action, reward, next_state, done) # record every trading \n",
    "        \n",
    "        # transit to next state\n",
    "        state = next_state\n",
    "        \n",
    "        # determine if the training is over or not\n",
    "        if done:\n",
    "            break\n",
    "            \n",
    "        # replay to train the network    \n",
    "        if len(agent.memory) > batch_size: # batch_size = 2 to make agent learn for every 3 trading events\n",
    "            agent.replay(batch_size)\n",
    "            \n",
    "    print(\"episode: {}/{}, e: {:.2}, rewards: {}\"\n",
    "                    .format(e, EPISODES, agent.epsilon, rewards))\n",
    "    history_1.append([e, time, agent.epsilon, rewards])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/cheng/opt/anaconda3/envs/portfolio/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/Users/cheng/opt/anaconda3/envs/portfolio/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py:3704: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable.debug_mode()`.\n",
      "  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n",
      "  1%|          | 1/100 [00:05<09:28,  5.74s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 0/100, e: 0.94, rewards: 1.5114835969498384\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  2%|▏         | 2/100 [00:13<11:37,  7.11s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 1/100, e: 0.86, rewards: 1.4361682103095597\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  3%|▎         | 3/100 [00:21<11:49,  7.32s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 2/100, e: 0.79, rewards: 1.5498683842038905\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  4%|▍         | 4/100 [00:30<12:32,  7.83s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 3/100, e: 0.73, rewards: 1.4524489991580327\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  5%|▌         | 5/100 [00:37<12:18,  7.77s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 4/100, e: 0.67, rewards: 1.6443779736264352\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  6%|▌         | 6/100 [00:45<12:16,  7.84s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 5/100, e: 0.61, rewards: 1.5249821208487324\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  7%|▋         | 7/100 [00:53<12:12,  7.87s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 6/100, e: 0.56, rewards: 1.5882407896299229\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  8%|▊         | 8/100 [01:03<13:15,  8.65s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 7/100, e: 0.52, rewards: 1.5875649062539117\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  9%|▉         | 9/100 [01:12<13:19,  8.78s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 8/100, e: 0.48, rewards: 1.4945008380948677\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 10%|█         | 10/100 [01:20<12:46,  8.52s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 9/100, e: 0.44, rewards: 1.5458187525020994\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 11%|█         | 11/100 [01:28<12:19,  8.31s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 10/100, e: 0.4, rewards: 1.296511047095364\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 12%|█▏        | 12/100 [01:37<12:13,  8.33s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 11/100, e: 0.37, rewards: 1.4182194540000683\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 13%|█▎        | 13/100 [01:45<12:01,  8.29s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 12/100, e: 0.34, rewards: 1.4909754365581167\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 14%|█▍        | 14/100 [01:52<11:28,  8.01s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 13/100, e: 0.31, rewards: 1.5933883288523436\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 15%|█▌        | 15/100 [01:59<11:02,  7.80s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 14/100, e: 0.29, rewards: 1.5512512683216255\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 16%|█▌        | 16/100 [02:07<10:41,  7.64s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 15/100, e: 0.26, rewards: 1.5400461083787267\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 17%|█▋        | 17/100 [02:14<10:22,  7.50s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 16/100, e: 0.24, rewards: 1.5174830936307417\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 18%|█▊        | 18/100 [02:22<10:17,  7.53s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 17/100, e: 0.22, rewards: 1.474712581353935\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 19%|█▉        | 19/100 [02:29<10:03,  7.45s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 18/100, e: 0.2, rewards: 1.4998871605883939\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 20%|██        | 20/100 [02:36<09:54,  7.43s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 19/100, e: 0.19, rewards: 1.475099133237893\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 21%|██        | 21/100 [02:43<09:41,  7.36s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 20/100, e: 0.17, rewards: 1.4832341811402752\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 22%|██▏       | 22/100 [02:51<09:34,  7.36s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 21/100, e: 0.16, rewards: 1.6185206851445328\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 23%|██▎       | 23/100 [02:58<09:23,  7.31s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 22/100, e: 0.14, rewards: 1.4706521009435336\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 24%|██▍       | 24/100 [03:05<09:13,  7.28s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 23/100, e: 0.13, rewards: 1.4542694546694799\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 25%|██▌       | 25/100 [03:13<09:09,  7.32s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 24/100, e: 0.12, rewards: 1.5085139834857035\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 26%|██▌       | 26/100 [03:20<09:02,  7.33s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 25/100, e: 0.11, rewards: 1.5702502231977116\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 27%|██▋       | 27/100 [03:27<09:00,  7.41s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 26/100, e: 0.1, rewards: 1.5331123224783316\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 28%|██▊       | 28/100 [03:35<08:51,  7.39s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 27/100, e: 0.094, rewards: 1.5410023367519683\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 29%|██▉       | 29/100 [03:42<08:48,  7.44s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 28/100, e: 0.087, rewards: 1.5244423214447334\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 30%|███       | 30/100 [03:50<08:40,  7.43s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 29/100, e: 0.08, rewards: 1.5221819066937623\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 31%|███       | 31/100 [03:57<08:36,  7.49s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 30/100, e: 0.073, rewards: 1.4532938388341679\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 32%|███▏      | 32/100 [04:05<08:26,  7.44s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 31/100, e: 0.067, rewards: 1.65865303634445\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 33%|███▎      | 33/100 [04:12<08:16,  7.42s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 32/100, e: 0.062, rewards: 1.384366864393528\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 34%|███▍      | 34/100 [04:20<08:11,  7.45s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 33/100, e: 0.057, rewards: 1.4618548438690482\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 35%|███▌      | 35/100 [04:27<08:03,  7.43s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 34/100, e: 0.052, rewards: 1.51251801844733\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 36%|███▌      | 36/100 [04:35<07:58,  7.48s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 35/100, e: 0.048, rewards: 1.5818395168318526\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 37%|███▋      | 37/100 [04:42<07:49,  7.45s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 36/100, e: 0.044, rewards: 1.4798275968512886\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 38%|███▊      | 38/100 [04:50<07:44,  7.50s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 37/100, e: 0.04, rewards: 1.562797508130004\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 39%|███▉      | 39/100 [04:57<07:35,  7.47s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 38/100, e: 0.037, rewards: 1.5344039115704373\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 40%|████      | 40/100 [05:05<07:29,  7.48s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 39/100, e: 0.034, rewards: 1.5073190087230788\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 41%|████      | 41/100 [05:12<07:22,  7.49s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 40/100, e: 0.031, rewards: 1.57851125412942\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 42%|████▏     | 42/100 [05:19<07:12,  7.46s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 41/100, e: 0.029, rewards: 1.625786560779943\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 43%|████▎     | 43/100 [05:27<07:08,  7.52s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 42/100, e: 0.026, rewards: 1.4231748073039057\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 44%|████▍     | 44/100 [05:35<07:02,  7.55s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 43/100, e: 0.024, rewards: 1.4672352323197142\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 45%|████▌     | 45/100 [05:42<06:56,  7.57s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 44/100, e: 0.022, rewards: 1.5328954909003927\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 46%|████▌     | 46/100 [05:50<06:46,  7.53s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 45/100, e: 0.02, rewards: 1.4974446748123151\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 47%|████▋     | 47/100 [05:57<06:40,  7.55s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 46/100, e: 0.019, rewards: 1.5656956366002677\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 48%|████▊     | 48/100 [06:05<06:30,  7.51s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 47/100, e: 0.017, rewards: 1.5777990307683811\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 49%|████▉     | 49/100 [06:12<06:24,  7.54s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 48/100, e: 0.016, rewards: 1.5550855724681014\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 50%|█████     | 50/100 [06:20<06:14,  7.50s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 49/100, e: 0.014, rewards: 1.4624250920640527\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 51%|█████     | 51/100 [06:27<06:05,  7.46s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 50/100, e: 0.013, rewards: 1.492149604431204\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 52%|█████▏    | 52/100 [06:35<06:00,  7.50s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 51/100, e: 0.012, rewards: 1.6173147154731535\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 53%|█████▎    | 53/100 [06:42<05:51,  7.48s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 52/100, e: 0.011, rewards: 1.4213452500819126\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 54%|█████▍    | 54/100 [06:50<05:45,  7.51s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 53/100, e: 0.01, rewards: 1.4632892785014369\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 55%|█████▌    | 55/100 [06:57<05:36,  7.48s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 54/100, e: 0.01, rewards: 1.3978625656305346\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 56%|█████▌    | 56/100 [07:05<05:33,  7.57s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 55/100, e: 0.01, rewards: 1.5411885460791612\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 57%|█████▋    | 57/100 [07:12<05:24,  7.55s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 56/100, e: 0.01, rewards: 1.4133025707670779\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 58%|█████▊    | 58/100 [07:20<05:18,  7.57s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 57/100, e: 0.01, rewards: 1.420090209620016\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 59%|█████▉    | 59/100 [07:27<05:08,  7.52s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 58/100, e: 0.01, rewards: 1.5397617446133027\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 60%|██████    | 60/100 [07:35<04:59,  7.49s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 59/100, e: 0.01, rewards: 1.5285201853366415\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 61%|██████    | 61/100 [07:43<04:53,  7.53s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 60/100, e: 0.01, rewards: 1.3605097961667805\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 62%|██████▏   | 62/100 [07:50<04:44,  7.49s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 61/100, e: 0.01, rewards: 1.48923272962952\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 63%|██████▎   | 63/100 [07:58<04:38,  7.52s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 62/100, e: 0.01, rewards: 1.6627059238702693\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 64%|██████▍   | 64/100 [08:05<04:29,  7.48s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 63/100, e: 0.01, rewards: 1.4871391874786077\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 65%|██████▌   | 65/100 [08:13<04:22,  7.51s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 64/100, e: 0.01, rewards: 1.4344345764356148\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 66%|██████▌   | 66/100 [08:20<04:14,  7.47s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 65/100, e: 0.01, rewards: 1.4709511321425048\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 67%|██████▋   | 67/100 [08:28<04:08,  7.53s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 66/100, e: 0.01, rewards: 1.5737260780648101\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 68%|██████▊   | 68/100 [08:35<04:01,  7.54s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 67/100, e: 0.01, rewards: 1.4344754260031916\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 69%|██████▉   | 69/100 [08:43<03:52,  7.50s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 68/100, e: 0.01, rewards: 1.474772889928426\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 70%|███████   | 70/100 [08:50<03:46,  7.54s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 69/100, e: 0.01, rewards: 1.314930722419385\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 71%|███████   | 71/100 [08:58<03:37,  7.50s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 70/100, e: 0.01, rewards: 1.4933500991472526\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 72%|███████▏  | 72/100 [09:05<03:31,  7.54s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 71/100, e: 0.01, rewards: 1.4105258899531326\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 73%|███████▎  | 73/100 [09:13<03:22,  7.49s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 72/100, e: 0.01, rewards: 1.5591342224156846\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 74%|███████▍  | 74/100 [09:20<03:15,  7.53s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 73/100, e: 0.01, rewards: 1.481283253965126\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 75%|███████▌  | 75/100 [09:28<03:07,  7.49s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 74/100, e: 0.01, rewards: 1.566481660055593\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 76%|███████▌  | 76/100 [09:35<03:00,  7.50s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 75/100, e: 0.01, rewards: 1.419343498393765\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 77%|███████▋  | 77/100 [09:43<02:51,  7.47s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 76/100, e: 0.01, rewards: 1.7480691428962654\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 78%|███████▊  | 78/100 [09:50<02:43,  7.45s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 77/100, e: 0.01, rewards: 1.5139052061475928\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 79%|███████▉  | 79/100 [09:58<02:37,  7.50s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 78/100, e: 0.01, rewards: 1.3807509407448841\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 80%|████████  | 80/100 [10:05<02:29,  7.46s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 79/100, e: 0.01, rewards: 1.6039580208059487\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 81%|████████  | 81/100 [10:13<02:22,  7.52s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 80/100, e: 0.01, rewards: 1.5516321367817958\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 82%|████████▏ | 82/100 [10:20<02:14,  7.49s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 81/100, e: 0.01, rewards: 1.464408623274913\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 83%|████████▎ | 83/100 [10:28<02:08,  7.53s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 82/100, e: 0.01, rewards: 1.553570359095182\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 84%|████████▍ | 84/100 [10:35<01:59,  7.49s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 83/100, e: 0.01, rewards: 1.5040864675948307\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 85%|████████▌ | 85/100 [10:43<01:52,  7.53s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 84/100, e: 0.01, rewards: 1.4794321386026554\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 86%|████████▌ | 86/100 [10:50<01:44,  7.49s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 85/100, e: 0.01, rewards: 1.4576506928324389\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 87%|████████▋ | 87/100 [10:58<01:37,  7.52s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 86/100, e: 0.01, rewards: 1.5410329291491454\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 88%|████████▊ | 88/100 [11:05<01:29,  7.48s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 87/100, e: 0.01, rewards: 1.52687826880751\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 89%|████████▉ | 89/100 [11:12<01:22,  7.46s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 88/100, e: 0.01, rewards: 1.6196696518257299\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 90%|█████████ | 90/100 [11:20<01:15,  7.51s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 89/100, e: 0.01, rewards: 1.5286589263143109\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 91%|█████████ | 91/100 [11:27<01:07,  7.48s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 90/100, e: 0.01, rewards: 1.5837018938117822\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 92%|█████████▏| 92/100 [11:35<01:00,  7.56s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 91/100, e: 0.01, rewards: 1.4825246536886256\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 93%|█████████▎| 93/100 [11:43<00:52,  7.51s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 92/100, e: 0.01, rewards: 1.544007871324209\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 94%|█████████▍| 94/100 [11:50<00:45,  7.54s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 93/100, e: 0.01, rewards: 1.5535341898794328\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 95%|█████████▌| 95/100 [11:58<00:37,  7.50s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 94/100, e: 0.01, rewards: 1.521378554870091\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 96%|█████████▌| 96/100 [12:05<00:30,  7.52s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 95/100, e: 0.01, rewards: 1.6919492527180708\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 97%|█████████▋| 97/100 [12:13<00:22,  7.49s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 96/100, e: 0.01, rewards: 1.6434065315890103\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 98%|█████████▊| 98/100 [12:20<00:14,  7.47s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 97/100, e: 0.01, rewards: 1.4426326860519474\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 99%|█████████▉| 99/100 [12:28<00:07,  7.55s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 98/100, e: 0.01, rewards: 1.5262979089853963\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 100/100 [12:35<00:00,  7.56s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 99/100, e: 0.01, rewards: 1.5460787303204409\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def training_plot(history):\n",
    "    df = pd.DataFrame(history, columns =[\"episode\", \"total_time\",\"epsilon\",'reward'])\n",
    "    df.set_index(\"episode\")\n",
    "    df.to_csv('../output/RL_training_data_1.jpg')\n",
    "    figs, axs = plt.subplots(nrows=2, ncols=1, figsize=(12, 6))\n",
    "\n",
    "    axs[0].set_title('Total Rewards for each episode')\n",
    "    axs[0].plot(df.index, df['reward'].rolling(5).mean())\n",
    "    axs[0].set_ylabel('total rewards')\n",
    "\n",
    "    axs[1].set_title('Epsilon(exploring rate) for each episode')\n",
    "    axs[1].plot(df.index, df['epsilon'])\n",
    "    axs[1].set_ylabel('epsilon')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # figs.savefig('../picture/RL_training_plots_1.jpg')\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "training_plot(history_1)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-d914d0510592>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-580d098a55d4>\u001b[0m in \u001b[0;36mtraining_plot\u001b[0;34m(history)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"episode\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../output/RL_training_data_1.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mfigs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mncols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Total Rewards for each episode'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Switch to other platform"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "train_envs = ts.env.DummyVectorEnv([lambda: gym.make('CartPole-v0') for _ in range(8)])\n",
    "test_envs = ts.env.DummyVectorEnv([lambda: gym.make('CartPole-v0') for _ in range(100)])\n",
    "\n",
    "env = gym.make('CartPole-v0')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "np.prod(state_shape)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "state_shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, state_shape, action_shape):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(*[\n",
    "            nn.Linear(np.prod(state_shape), 128), nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 128), nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 128), nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, np.prod(action_shape))\n",
    "        ])\n",
    "    def forward(self, obs, state=None, info={}):\n",
    "        if not isinstance(obs, torch.Tensor):\n",
    "            obs = torch.tensor(obs, dtype=torch.float)\n",
    "        batch = obs.shape[0]\n",
    "        logits = self.model(obs.view(batch, -1))\n",
    "        return logits, state\n",
    "\n",
    "state_shape = env.observation_space.shape or env.observation_space.n\n",
    "action_shape = env.action_space.shape or env.action_space.n\n",
    "net = Net(state_shape, action_shape)\n",
    "optim = torch.optim.Adam(net.parameters(), lr=1e-3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "net.parameters"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<bound method Module.parameters of Net(\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=128, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=128, out_features=2, bias=True)\n",
       "  )\n",
       ")>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "policy = ts.policy.DQNPolicy(net, optim, discount_factor=0.9, estimation_step=3, target_update_freq=320)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "train_collector = ts.data.Collector(policy, train_envs, ts.data.VectorReplayBuffer(20000, 10), exploration_noise=True)\n",
    "test_collector = ts.data.Collector(policy, test_envs, exploration_noise=True)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "result = ts.trainer.offpolicy_trainer(\n",
    "    policy, \n",
    "    train_collector, \n",
    "    test_collector,\n",
    "    max_epoch=10, \n",
    "    step_per_epoch=10000, \n",
    "    step_per_collect=10,\n",
    "    update_per_step=0.1, \n",
    "    episode_per_test=100,\n",
    "    batch_size=64,\n",
    "    train_fn=lambda epoch, env_step: policy.set_eps(0.1),\n",
    "    test_fn=lambda epoch, env_step: policy.set_eps(0.05),\n",
    "    stop_fn=lambda mean_rewards: mean_rewards >= env.spec.reward_threshold)\n",
    "print(f'Finished training! Use {result[\"duration\"]}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch #1:   0%|          | 0/10000 [00:00<?, ?it/s]/Users/cheng/opt/anaconda3/envs/portfolio/lib/python3.7/site-packages/tianshou/data/collector.py:177: UserWarning: n_step=10 is not a multiple of #env (8), which may cause extra transitions collected into the buffer.\n",
      "  f\"n_step={n_step} is not a multiple of #env ({self.env_num}), \"\n",
      "Epoch #1:  47%|####7     | 4736/10000 [00:03<00:04, 1195.54it/s, env_step=4736, len=200, n/ep=1, n/st=16, rew=200.00]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Finished training! Use 4.10s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "policy.eval()\n",
    "policy.set_eps(0.05)\n",
    "collector = ts.data.Collector(policy, env, exploration_noise=True)\n",
    "collector.collect(n_episode=1, render=1 / 35)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/cheng/opt/anaconda3/envs/portfolio/lib/python3.7/site-packages/tianshou/data/collector.py:60: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'n/ep': 1,\n",
       " 'n/st': 200,\n",
       " 'rews': array([200.]),\n",
       " 'lens': array([200]),\n",
       " 'idxs': array([0])}"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "writer = SummaryWriter('log/dqn')\n",
    "logger = BasicLogger(writer)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "result"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'test_step': 22037,\n",
       " 'test_episode': 200,\n",
       " 'test_time': '0.91s',\n",
       " 'test_speed': '24227.64 step/s',\n",
       " 'best_reward': 198.07,\n",
       " 'best_result': '198.07 ± 4.76',\n",
       " 'duration': '4.10s',\n",
       " 'train_time/model': '2.52s',\n",
       " 'train_step': 4736,\n",
       " 'train_episode': 233,\n",
       " 'train_time/collector': '0.67s',\n",
       " 'train_speed': '1484.76 step/s'}"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b53c6b2144c6d5beb75ad69fe16fdbe69133743e5c9fe49bc51d79f07f4417c1"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('portfolio': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}